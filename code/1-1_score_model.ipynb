{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CV Job Matching using Doc2Vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementation\n",
    "\n",
    "To match CVs to jobs using Doc2Vec, we first import needed libraries and load job data from a CSV file. We clean up the data, keep only the important columns, and combine them into a new column called 'data.' Then, we break down the words in the 'data' column and tag them with unique IDs using the TaggedDocument class.\n",
    "\n",
    "Next, we set up the Doc2Vec model with certain settings, like the size of the vector, minimum count, and number of times to run. We create the vocabulary by giving the tagged data to the model, and then train the model on this data.\n",
    "\n",
    "After training, we save the model for later use. We create perfect resumes from each job description to test our model. To match a resume with a job description, we load the saved model and clean up the resume and job description text. We clean the data, making them lowercase, and removing punctuation, and etc.\n",
    "\n",
    "Using the trained model, we get the document vectors for the resume and job description. Then, we find the cosine similarity between the two vectors to see how well the resume and the job description match. We do this for both a random resume and the perfect resume. The cosine similarity score is between -1 and 1, with 1 being a perfect match and -1 being no match at all.\n",
    "\n",
    "By using Doc2Vec and cosine similarity, we can match job descriptions and resumes quickly and effectively. This makes the job application process easier and increases the chances of finding the right person for the job.\n",
    "\n",
    "Lastly, we use a Gauge chart to show the matching percentage for both scores. This gives users a threshold that they could consider when changing their CV to pass the Application Tracking System (ATS) used by most employers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Coding\n",
    "#### 1. Set up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "YDFUjQi3S171"
   },
   "outputs": [],
   "source": [
    "## Install all dependencies\n",
    "# !pip install gensim\n",
    "# !pip install nltk\n",
    "# !pip install pandas\n",
    "# !pip install numpy\n",
    "# !pip install requests\n",
    "# !pip install PyPDF2\n",
    "# !pip install termcolor\n",
    "# !pip install python-docx\n",
    "# !pip install spacy\n",
    "# !python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "kpZnVCxZSQ8a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/hh1980/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import libraries\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "from nltk.tokenize import word_tokenize\n",
    "from numpy.linalg import norm\n",
    "from termcolor import colored\n",
    "from docx import Document\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "import PyPDF2\n",
    "import re\n",
    "import plotly.graph_objects as go\n",
    "import os\n",
    "import random\n",
    "import nltk\n",
    "import spacy\n",
    "import json\n",
    "from docx import Document\n",
    "from docx.shared import Inches\n",
    "from spacy.matcher import Matcher\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Prepare data\n",
    "Prepare data from dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 182
    },
    "id": "5CoVK6-iSWsU",
    "outputId": "20a60cf2-8224-47a2-d43c-b20d351db269"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>index</th>\n",
       "      <th>Job Title</th>\n",
       "      <th>Salary Estimate</th>\n",
       "      <th>Job Description</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Company Name</th>\n",
       "      <th>Location</th>\n",
       "      <th>Headquarters</th>\n",
       "      <th>Size</th>\n",
       "      <th>Founded</th>\n",
       "      <th>Type of ownership</th>\n",
       "      <th>Industry</th>\n",
       "      <th>Sector</th>\n",
       "      <th>Revenue</th>\n",
       "      <th>Competitors</th>\n",
       "      <th>Easy Apply</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>$111K-$181K (Glassdoor est.)</td>\n",
       "      <td>ABOUT HOPPER\\n\\nAt Hopper, we’re on a mission ...</td>\n",
       "      <td>3.5</td>\n",
       "      <td>Hopper\\n3.5</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>Montreal, Canada</td>\n",
       "      <td>501 to 1000 employees</td>\n",
       "      <td>2007</td>\n",
       "      <td>Company - Private</td>\n",
       "      <td>Travel Agencies</td>\n",
       "      <td>Travel &amp; Tourism</td>\n",
       "      <td>Unknown / Non-Applicable</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Data Scientist, Product Analytics</td>\n",
       "      <td>$111K-$181K (Glassdoor est.)</td>\n",
       "      <td>At Noom, we use scientifically proven methods ...</td>\n",
       "      <td>4.5</td>\n",
       "      <td>Noom US\\n4.5</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>1001 to 5000 employees</td>\n",
       "      <td>2008</td>\n",
       "      <td>Company - Private</td>\n",
       "      <td>Health, Beauty, &amp; Fitness</td>\n",
       "      <td>Consumer Services</td>\n",
       "      <td>Unknown / Non-Applicable</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>Data Science Manager</td>\n",
       "      <td>$111K-$181K (Glassdoor est.)</td>\n",
       "      <td>Decode_M\\n\\nhttps://www.decode-m.com/\\n\\nData ...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>Decode_M</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>1 to 50 employees</td>\n",
       "      <td>-1</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>Unknown / Non-Applicable</td>\n",
       "      <td>-1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>$111K-$181K (Glassdoor est.)</td>\n",
       "      <td>Sapphire Digital seeks a dynamic and driven mi...</td>\n",
       "      <td>3.4</td>\n",
       "      <td>Sapphire Digital\\n3.4</td>\n",
       "      <td>Lyndhurst, NJ</td>\n",
       "      <td>Lyndhurst, NJ</td>\n",
       "      <td>201 to 500 employees</td>\n",
       "      <td>2019</td>\n",
       "      <td>Company - Private</td>\n",
       "      <td>Internet</td>\n",
       "      <td>Information Technology</td>\n",
       "      <td>Unknown / Non-Applicable</td>\n",
       "      <td>Zocdoc, Healthgrades</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>Director, Data Science</td>\n",
       "      <td>$111K-$181K (Glassdoor est.)</td>\n",
       "      <td>Director, Data Science - (200537)\\nDescription...</td>\n",
       "      <td>3.4</td>\n",
       "      <td>United Entertainment Group\\n3.4</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>51 to 200 employees</td>\n",
       "      <td>2007</td>\n",
       "      <td>Company - Private</td>\n",
       "      <td>Advertising &amp; Marketing</td>\n",
       "      <td>Business Services</td>\n",
       "      <td>Unknown / Non-Applicable</td>\n",
       "      <td>BBDO, Grey Group, Droga5</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  index                          Job Title  \\\n",
       "0           0      0              Senior Data Scientist   \n",
       "1           1      1  Data Scientist, Product Analytics   \n",
       "2           2      2               Data Science Manager   \n",
       "3           3      3                       Data Analyst   \n",
       "4           4      4             Director, Data Science   \n",
       "\n",
       "                Salary Estimate  \\\n",
       "0  $111K-$181K (Glassdoor est.)   \n",
       "1  $111K-$181K (Glassdoor est.)   \n",
       "2  $111K-$181K (Glassdoor est.)   \n",
       "3  $111K-$181K (Glassdoor est.)   \n",
       "4  $111K-$181K (Glassdoor est.)   \n",
       "\n",
       "                                     Job Description  Rating  \\\n",
       "0  ABOUT HOPPER\\n\\nAt Hopper, we’re on a mission ...     3.5   \n",
       "1  At Noom, we use scientifically proven methods ...     4.5   \n",
       "2  Decode_M\\n\\nhttps://www.decode-m.com/\\n\\nData ...    -1.0   \n",
       "3  Sapphire Digital seeks a dynamic and driven mi...     3.4   \n",
       "4  Director, Data Science - (200537)\\nDescription...     3.4   \n",
       "\n",
       "                      Company Name       Location      Headquarters  \\\n",
       "0                      Hopper\\n3.5   New York, NY  Montreal, Canada   \n",
       "1                     Noom US\\n4.5   New York, NY      New York, NY   \n",
       "2                         Decode_M   New York, NY      New York, NY   \n",
       "3            Sapphire Digital\\n3.4  Lyndhurst, NJ     Lyndhurst, NJ   \n",
       "4  United Entertainment Group\\n3.4   New York, NY      New York, NY   \n",
       "\n",
       "                     Size  Founded  Type of ownership  \\\n",
       "0   501 to 1000 employees     2007  Company - Private   \n",
       "1  1001 to 5000 employees     2008  Company - Private   \n",
       "2       1 to 50 employees       -1            Unknown   \n",
       "3    201 to 500 employees     2019  Company - Private   \n",
       "4     51 to 200 employees     2007  Company - Private   \n",
       "\n",
       "                    Industry                  Sector  \\\n",
       "0            Travel Agencies        Travel & Tourism   \n",
       "1  Health, Beauty, & Fitness       Consumer Services   \n",
       "2                         -1                      -1   \n",
       "3                   Internet  Information Technology   \n",
       "4    Advertising & Marketing       Business Services   \n",
       "\n",
       "                    Revenue               Competitors Easy Apply  \n",
       "0  Unknown / Non-Applicable                        -1         -1  \n",
       "1  Unknown / Non-Applicable                        -1         -1  \n",
       "2  Unknown / Non-Applicable                        -1       True  \n",
       "3  Unknown / Non-Applicable      Zocdoc, Healthgrades         -1  \n",
       "4  Unknown / Non-Applicable  BBDO, Grey Group, Droga5         -1  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load data\n",
    "df = pd.read_csv('./dataset/DataScientist.csv')\n",
    "# Check data\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since head() fuction does not show all data, we check column names to retain only necessary variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'index', 'Job Title', 'Salary Estimate',\n",
       "       'Job Description', 'Rating', 'Company Name', 'Location', 'Headquarters',\n",
       "       'Size', 'Founded', 'Type of ownership', 'Industry', 'Sector', 'Revenue',\n",
       "       'Competitors', 'Easy Apply'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show column name\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keep only some columns to train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job Title</th>\n",
       "      <th>Job Description</th>\n",
       "      <th>Industry</th>\n",
       "      <th>Sector</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>ABOUT HOPPER\\n\\nAt Hopper, we’re on a mission ...</td>\n",
       "      <td>Travel Agencies</td>\n",
       "      <td>Travel &amp; Tourism</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Scientist, Product Analytics</td>\n",
       "      <td>At Noom, we use scientifically proven methods ...</td>\n",
       "      <td>Health, Beauty, &amp; Fitness</td>\n",
       "      <td>Consumer Services</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Science Manager</td>\n",
       "      <td>Decode_M\\n\\nhttps://www.decode-m.com/\\n\\nData ...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Sapphire Digital seeks a dynamic and driven mi...</td>\n",
       "      <td>Internet</td>\n",
       "      <td>Information Technology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Director, Data Science</td>\n",
       "      <td>Director, Data Science - (200537)\\nDescription...</td>\n",
       "      <td>Advertising &amp; Marketing</td>\n",
       "      <td>Business Services</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Job Title  \\\n",
       "0              Senior Data Scientist   \n",
       "1  Data Scientist, Product Analytics   \n",
       "2               Data Science Manager   \n",
       "3                       Data Analyst   \n",
       "4             Director, Data Science   \n",
       "\n",
       "                                     Job Description  \\\n",
       "0  ABOUT HOPPER\\n\\nAt Hopper, we’re on a mission ...   \n",
       "1  At Noom, we use scientifically proven methods ...   \n",
       "2  Decode_M\\n\\nhttps://www.decode-m.com/\\n\\nData ...   \n",
       "3  Sapphire Digital seeks a dynamic and driven mi...   \n",
       "4  Director, Data Science - (200537)\\nDescription...   \n",
       "\n",
       "                    Industry                  Sector  \n",
       "0            Travel Agencies        Travel & Tourism  \n",
       "1  Health, Beauty, & Fitness       Consumer Services  \n",
       "2                         -1                      -1  \n",
       "3                   Internet  Information Technology  \n",
       "4    Advertising & Marketing       Business Services  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df =df[['Job Title', 'Job Description', 'Industry', 'Sector']]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>Job Title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Senior Data Analyst</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2074</th>\n",
       "      <td>Phoenix Data Science Tutor Jobs</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2075</th>\n",
       "      <td>Civil Engineer/GIS Data Analyst</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2076</th>\n",
       "      <td>Principal Device Modeling Engineer</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2077</th>\n",
       "      <td>SQL/SAS Data Analyst</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2078</th>\n",
       "      <td>Patient Safety Physician or Safety Scientist -...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2079 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  index  Job Title\n",
       "0                                        Data Scientist        274\n",
       "1                                         Data Engineer        260\n",
       "2                                          Data Analyst        246\n",
       "3                                 Senior Data Scientist         91\n",
       "4                                   Senior Data Analyst         47\n",
       "...                                                 ...        ...\n",
       "2074                    Phoenix Data Science Tutor Jobs          1\n",
       "2075                    Civil Engineer/GIS Data Analyst          1\n",
       "2076                 Principal Device Modeling Engineer          1\n",
       "2077                               SQL/SAS Data Analyst          1\n",
       "2078  Patient Safety Physician or Safety Scientist -...          1\n",
       "\n",
       "[2079 rows x 2 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job_title = df['Job Title'].value_counts().reset_index()\n",
    "job_title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                data\n",
      "0  Senior Data Scientist ABOUT HOPPER\\n\\nAt Hoppe...\n",
      "1  Data Scientist, Product Analytics At Noom, we ...\n",
      "2  Data Science Manager Decode_M\\n\\nhttps://www.d...\n",
      "3  Data Analyst Sapphire Digital seeks a dynamic ...\n",
      "4  Director, Data Science Director, Data Science ...\n"
     ]
    }
   ],
   "source": [
    "# Create a new column called 'data' and merge the values of the other columns into it\n",
    "df['data'] = df[['Job Title', 'Job Description', 'Industry', 'Sector']].apply(lambda x: ' '.join(x.dropna().astype(str)), axis=1)\n",
    "# Drop the individual columns if you no longer need them\n",
    "df.drop(['Job Title', 'Job Description', 'Industry', 'Sector'], axis=1, inplace=True)\n",
    "# Preview the updated dataframe\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Tokenize data\n",
    "We tokenize the words in the 'data' column and tag them with unique identifiers using the TaggedDocument class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "sCAMBUD8Sorw"
   },
   "outputs": [],
   "source": [
    "# Tag data\n",
    "data = list(df['data'])\n",
    "tagged_data = [TaggedDocument(words = word_tokenize(_d.lower()), tags = [str(i)]) for i, _d in enumerate(data)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Model initialization and vocabulary buiding\n",
    "Next, we initialize the Doc2Vec model with specific parameters.\n",
    "\n",
    "**Parameters** of Doc2Vec are as follows: \n",
    "\n",
    "- `vector_size`: Dimensionality of the feature vectors. Default: 100.\n",
    "- `window`: The window refers to the maximum distance between the target word and its context words within a sentence. Default: 5.\n",
    "- `min_count`: Ignores all words with a total frequency lower than this. Default: 5.\n",
    "- `epochs`: Number of iterations (epochs) over the corpus. Defaults to 5 for PV-DBOW and 10 for PV-DM.\n",
    "- `dm`: Defines the training algorithm. If `dm = 1`, the Distributed Memory (PV-DM) model is used. If `dm = 0`, the Distributed Bag of Words (PV-DBOW) model is used. Default: 1 (PV-DM).\n",
    "- `dbow_words`: If set to 1, trains word vectors (in addition to document vectors) using the PV-DBOW algorithm. Default: 0 (False).\n",
    "- `dm_mean`: If set to 1, uses the mean of the context word vectors instead of concatenation when inferring vectors in the PV-DM model. Default: 0 (False).\n",
    "- `dm_concat`: If set to 1, concatenates the document and context word vectors when inferring vectors in the PV-DM model. Default: 0 (False).\n",
    "- `dm_tag_count`: Expected number of document tags per document, when using the PV-DM algorithm. Default: 1.\n",
    "- `dbow_tag_count`: Expected number of document tags per document, when using the PV-DBOW algorithm. Default: 1.\n",
    "- `alpha`: The initial learning rate. Default: 0.025.\n",
    "- `min_alpha`: The learning rate will linearly drop to `min_alpha` as training progresses. Default: 0.0001.\n",
    "- `hs`: If set to 1, hierarchical softmax activation function will be used. Default: 0 (Negative Sampling).\n",
    "- `negative`: If > 0, negative sampling will be used, the int for negative specifies how many \"noise words\" should be drawn. Default: 5.\n",
    "- `ns_exponent`: The exponent used to shape the negative sampling distribution. Default: 0.75.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "pN_H6onBTamK"
   },
   "outputs": [],
   "source": [
    "# Model initialization\n",
    "model = Doc2Vec(vector_size = 50,\n",
    "min_count = 5,\n",
    "epochs = 100,\n",
    "alpha = 0.001\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "Sv_Mtx4OWFgF"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11885\n"
     ]
    }
   ],
   "source": [
    "# Vocabulary building\n",
    "model.build_vocab(tagged_data)\n",
    "# Get the vocabulary keys\n",
    "keys = model.wv.key_to_index.keys()\n",
    "# Print the length of the vocabulary keys\n",
    "print(len(keys))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. Train and save the model\n",
    "Train the model on tagged data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0jwx4eNAWYrI"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training epoch 1/100\n",
      "Training epoch 2/100\n",
      "Training epoch 3/100\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "for epoch in range(model.epochs):\n",
    "    print(f\"Training epoch {epoch+1}/{model.epochs}\")\n",
    "    model.train(tagged_data, \n",
    "                total_examples=model.corpus_count, \n",
    "                epochs=model.epochs)\n",
    "\n",
    "model.save('cv_job_maching.model')\n",
    "print(\"Model saved\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6. Generate perfect resumes for job description for validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the spaCy English language model\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Extract Job Requirements\n",
    "def extract_requirements(job_description):\n",
    "    # Use spaCy to extract skills, experience, and education\n",
    "    doc = nlp(job_description)\n",
    "    skills = extract_skills(doc)\n",
    "    experience = extract_experience(doc)\n",
    "    education = extract_education(doc)\n",
    "\n",
    "    return {\n",
    "        'skills': skills,\n",
    "        'experience': experience,\n",
    "        'education': education\n",
    "    }\n",
    "\n",
    "def extract_skills(doc):\n",
    "    # Define patterns to match skills\n",
    "    skill_patterns = [\n",
    "        [{'POS': 'NOUN'}, {'LOWER': 'skills'}],\n",
    "        [{'POS': 'NOUN'}, {'LOWER': 'experience'}, {'LOWER': 'in'}],\n",
    "        [{'POS': 'NOUN'}, {'POS': 'CCONJ'}, {'POS': 'NOUN'}],  # e.g., \"Python and SQL\"\n",
    "        [{'POS': 'NOUN'}, {'POS': 'PART'}, {'POS': 'NOUN'}],   # e.g., \"Machine Learning\"\n",
    "        [{'POS': 'NOUN'}, {'POS': 'NOUN'}]                     # e.g., \"Data Analysis\"\n",
    "    ]\n",
    "    matcher = Matcher(nlp.vocab)\n",
    "    matcher.add(\"SKILLS\", skill_patterns)\n",
    "\n",
    "    skills = []\n",
    "    matches = matcher(doc)\n",
    "    for match_id, start, end in matches:\n",
    "        span = doc[start:end]\n",
    "        skills.append(span.text)\n",
    "\n",
    "    # Remove duplicates and join skills with commas\n",
    "    skills = list(set(skills))\n",
    "    return ', '.join(skills)\n",
    "\n",
    "def extract_experience(doc):\n",
    "    # Define patterns to match experience requirements\n",
    "    exp_patterns = [\n",
    "        [{'LOWER': 'experience'}, {'POS': 'NUM'}, {'LOWER': 'years'}],\n",
    "        [{'LOWER': 'minimum'}, {'POS': 'NUM'}, {'LOWER': 'years'}, {'LOWER': 'experience'}]\n",
    "    ]\n",
    "    matcher = Matcher(nlp.vocab)\n",
    "    matcher.add(\"EXPERIENCE\", exp_patterns)\n",
    "\n",
    "    experience = []\n",
    "    matches = matcher(doc)\n",
    "    for match_id, start, end in matches:\n",
    "        span = doc[start:end]\n",
    "        experience.append(span.text)\n",
    "\n",
    "    return experience\n",
    "\n",
    "def extract_education(doc):\n",
    "    # Define patterns to match education requirements\n",
    "    edu_patterns = [\n",
    "        [{'LOWER': 'degree'}, {'POS': 'NOUN'}],\n",
    "        [{'LOWER': 'bachelor'}, {'POS': 'NOUN'}],\n",
    "        [{'LOWER': 'master'}, {'POS': 'NOUN'}]\n",
    "    ]\n",
    "    matcher = Matcher(nlp.vocab)\n",
    "    matcher.add(\"EDUCATION\", edu_patterns)\n",
    "\n",
    "    education = []\n",
    "    matches = matcher(doc)\n",
    "    for match_id, start, end in matches:\n",
    "        span = doc[start:end]\n",
    "        education.append(span.text)\n",
    "\n",
    "    return education"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill the Resume Template\n",
    "def fill_resume_template(job_description, template):\n",
    "    # Extract requirements from job description\n",
    "    requirements = extract_requirements(job_description)\n",
    "\n",
    "    # Fill the template with the requirements\n",
    "    resume = template.copy()\n",
    "    resume['Skills'] = ', '.join(requirements['skills'])\n",
    "    resume['Work Experience'] = [create_work_experience(req, requirements['skills']) for req in requirements['experience']]\n",
    "    resume['Education'] = create_education(requirements['education'][0]) if requirements['education'] else None\n",
    "\n",
    "    # Add relevant sections for data science roles\n",
    "    resume['Programming Languages'] = ', '.join(get_programming_languages(requirements['skills']))\n",
    "    resume['Data Science Skills'] = ', '.join(get_data_science_skills(requirements['skills']))\n",
    "    resume['Tools & Technologies'] = ', '.join(get_tools_and_technologies(requirements['skills']))\n",
    "\n",
    "    # Differentiate resumes based on specific requirements\n",
    "    resume['Domain Expertise'] = ', '.join(get_domain_expertise(job_description))\n",
    "    resume['Specialized Skills'] = ', '.join(get_specialized_skills(job_description))\n",
    "\n",
    "    return resume\n",
    "\n",
    "def create_work_experience(experience_requirement, skills):\n",
    "    # Parse the experience requirement\n",
    "    match = re.search(r'(\\d+)\\s*years', experience_requirement, re.I)\n",
    "    if match:\n",
    "        years = int(match.group(1))\n",
    "        position = 'Data Scientist' if 'data scientist' in experience_requirement.lower() else 'Relevant Position'\n",
    "        return {\n",
    "            'Position': position,\n",
    "            'Company': 'Relevant Company',\n",
    "            'Duration': f'{years} years',\n",
    "            'Responsibilities': ', '.join(skills)\n",
    "        }\n",
    "    return None\n",
    "\n",
    "def create_education(education_requirement):\n",
    "    # Parse the education requirement\n",
    "    degree_match = re.search(r'(bachelor|master|phd)\\s*(degree|\\'s)', education_requirement, re.I)\n",
    "    if degree_match:\n",
    "        degree_type = degree_match.group(1).capitalize()\n",
    "        return {\n",
    "            'Degree': f'{degree_type} Degree',\n",
    "            'Field': 'Data Science, Statistics, Computer Science, or related field',\n",
    "            'University': 'Relevant University'\n",
    "        }\n",
    "    return None\n",
    "\n",
    "def get_programming_languages(skills):\n",
    "    languages = ['Python', 'R', 'SQL', 'Java', 'C++', 'C', 'Scala', 'Julia', 'MATLAB', 'JavaScript', 'Ruby', 'Go', 'Kotlin', 'PHP', 'Swift', 'TypeScript', 'Perl', 'Bash', 'Shell Scripting', 'SAS', 'PL/SQL', 'VBA', 'F#', 'Clojure', 'Erlang', 'Rust', 'PowerShell', 'Dart','Hive', 'Objective-C']\n",
    "\n",
    "    return [lang for lang in languages if lang.lower() in [skill.lower() for skill in skills]]\n",
    "\n",
    "def get_data_science_skills(skills):\n",
    "    data_science_skills = [\n",
    "    'Machine Learning', 'Statistical Modeling', 'Data Analysis', 'Data Visualization',\n",
    "    'Deep Learning', 'Natural Language Processing', 'Computer Vision', 'Reinforcement Learning',\n",
    "    'Predictive Modeling', 'Time Series Analysis', 'Bayesian Methods', 'Survival Analysis',\n",
    "    'Experiment Design', 'A/B Testing', 'Dimensionality Reduction', 'Cluster Analysis',\n",
    "    'Anomaly Detection', 'Neural Networks', 'Optimization Techniques', 'Feature Engineering',\n",
    "    'Model Validation', 'Decision Trees', 'Random Forests', 'Gradient Boosting Machines',\n",
    "    'Support Vector Machines', 'Ensemble Methods', 'Recommendation Systems', 'Graph Analytics',\n",
    "    'Natural Language Generation', 'Sentiment Analysis', 'Text Mining', 'Image Processing',\n",
    "    'Speech Recognition', 'Pattern Recognition', 'Big Data Technologies', 'Causal Inference',\n",
    "    'Monte Carlo Methods', 'Simulation Techniques', 'Scalable Data Systems', 'Cloud Computing',\n",
    "    'Ethics in Data Science', 'Data Governance', 'Data Privacy', 'Data Security', 'Data Quality Management',\n",
    "    'Data Wrangling', 'Data Integration', 'Business Intelligence', 'Operational Research', 'Geospatial Analysis',\n",
    "    'Bioinformatics', 'Healthcare Analytics', 'Financial Modeling', 'Customer Analytics', 'Retail Analytics',\n",
    "    'Sports Analytics', 'Algorithm Development'\n",
    "]\n",
    "\n",
    "    return [skill for skill in data_science_skills if any(s.lower() in skill.lower() for s in skills)]\n",
    "\n",
    "def get_tools_and_technologies(skills):\n",
    "    tools_and_technologies = [\n",
    "    'Pandas', 'NumPy', 'Scikit-learn', 'TensorFlow', 'PyTorch', 'Keras', 'Spark', 'Hadoop', 'Hive', 'Impala',\n",
    "    'MapReduce', 'Pig', 'MongoDB', 'Postgres', 'NoSQL', 'MySQL', 'Oracle', 'SQL Server', 'Beautifulsoup', 'Selenium',\n",
    "    'Scrapy', 'HTML5', 'JavaScript', 'CSS', 'R Shiny', 'Tableau', 'Power BI', 'D3.js', 'Matplotlib', 'Seaborn',\n",
    "    'Plotly', 'Bokeh', 'ggplot2', 'Dask', 'Flink', 'Airflow', 'Luigi', 'Docker', 'Kubernetes', 'Jupyter',\n",
    "    'Zeppelin', 'Google BigQuery', 'Amazon Redshift', 'Azure Data Lake', 'Snowflake', 'Elasticsearch', 'Kibana',\n",
    "    'Logstash', 'Cassandra', 'Redis', 'Apache Kafka', 'RabbitMQ', 'Git', 'SVN', 'Jenkins', 'CI/CD Pipelines',\n",
    "    'Ansible', 'Terraform', 'Vault', 'Prometheus', 'Grafana', 'Apache Beam', 'Apache Storm', 'Neo4j', 'GraphQL',\n",
    "    'REST APIs', 'SOAP APIs', 'FastAPI', 'Flask', 'Django', 'OpenCV', 'scipy', 'Statsmodels', 'SymPy', 'XGBoost',\n",
    "    'LightGBM', 'CatBoost', 'MLflow', 'Tidyverse', 'Dash', 'Streamlit', 'Cytoscape.js', 'Vega-Lite', 'Altair',\n",
    "    'Apache Solr', 'JanusGraph', 'ArangoDB', 'Apache Nifi', 'Apache Sqoop', 'Apache Druid', 'Qlik Sense', 'Looker',\n",
    "    'Apache Superset', 'Metabase', 'SAS', 'SPSS', 'Stata', 'Vowpal Wabbit', 'Alteryx', 'KNIME'\n",
    "]\n",
    "\n",
    "    return [tool for tool in tools_and_technologies if any(s.lower() in tool.lower() for s in skills)]\n",
    "\n",
    "def get_domain_expertise(job_description):\n",
    "    domains = [\n",
    "    'Healthcare', 'Finance', 'Retail', 'Marketing', 'Telecommunications', 'Manufacturing', 'Energy',\n",
    "    'Transportation', 'Government', 'Defense', 'Security', 'Education', 'Real Estate', 'Sports',\n",
    "    'Entertainment', 'Media', 'Tourism', 'Hospitality', 'Legal', 'Insurance', 'Biotechnology',\n",
    "    'Pharmaceuticals', 'Agriculture', 'Food and Beverage', 'Environmental Science', 'Marine Science',\n",
    "    'Urban Planning', 'Public Health', 'E-commerce', 'Automotive', 'Aerospace', 'Utilities',\n",
    "    'Non-profit Sector', 'Human Resources', 'Supply Chain', 'Logistics', 'Construction',\n",
    "    'Mining', 'Oil and Gas', 'Publishing', 'Fintech', 'Edtech', 'Medtech', 'Adtech', 'Cryptocurrency',\n",
    "    'Blockchain', 'Gaming', 'Virtual Reality', 'Augmented Reality', 'Machine Learning as a Service',\n",
    "    'Cloud Services', 'IoT (Internet of Things)', 'Smart Cities', 'Cybersecurity', 'Forensics',\n",
    "    'Demography', 'Economic Analysis', 'Social Media', 'Content Creation', 'Digital Health', 'Telemedicine'\n",
    "]\n",
    "\n",
    "    return [domain for domain in domains if domain.lower() in job_description.lower()]\n",
    "\n",
    "def get_specialized_skills(job_description):\n",
    "    specialized_skills = [\n",
    "    'Recommender Systems', 'Natural Language Processing', 'Computer Vision', 'Time Series Analysis',\n",
    "    'Forecasting', 'Clustering', 'Ensemble Methods', 'Bayesian Methods', 'Neural Networks',\n",
    "    'Deep Learning', 'Reinforcement Learning', 'Collaborative Filtering', 'Web Scraping',\n",
    "    'Anomaly Detection', 'Dimensionality Reduction', 'Feature Selection', 'Feature Engineering',\n",
    "    'Model Deployment', 'Model Monitoring', 'Model Optimization', 'Hyperparameter Tuning',\n",
    "    'Data Imputation', 'Data Normalization', 'Data Labeling', 'Sentiment Analysis', 'Text Mining',\n",
    "    'Image Recognition', 'Speech Recognition', 'Audio Analysis', 'Signal Processing',\n",
    "    'Genetic Algorithms', 'Optimization Algorithms', 'Simulation', 'Statistical Inference',\n",
    "    'Causal Analysis', 'Graph Analytics', 'Social Network Analysis', 'Biostatistics',\n",
    "    'Epidemiology Modeling', 'Credit Risk Modeling', 'Fraud Detection', 'Algorithmic Trading',\n",
    "    'Robotics', 'Quantum Computing', 'Privacy-preserving ML', 'Federated Learning',\n",
    "    'Transfer Learning', 'Multi-task Learning', 'Geospatial Analysis', 'Remote Sensing',\n",
    "    'Computer-Aided Diagnosis', 'Precision Medicine', 'Blockchain Analytics', 'IoT Data Analysis',\n",
    "    'Predictive Maintenance', 'Supply Chain Analytics', 'Real-Time Data Processing',\n",
    "    'Customer Segmentation', 'Market Basket Analysis', 'Churn Prediction'\n",
    "]\n",
    "\n",
    "    return [skill for skill in specialized_skills if any(s.lower() in job_description.lower() for s in skill.split())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Resume Template\n",
    "resume_template = {\n",
    "    'Personal Information': {\n",
    "        'Name': '',\n",
    "    },\n",
    "    'Skills': '',\n",
    "    'Work Experience': [],\n",
    "    'Education': {},\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate Perfect Resumes\n",
    "perfect_resumes = []\n",
    "for job_description in df['data']:\n",
    "    perfect_resume = fill_resume_template(job_description, resume_template)\n",
    "    perfect_resumes.append(perfect_resume)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a directory to save the resumes\n",
    "save_dir = 'perfect_resumes'\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "# Save each perfect resume as a .docx file\n",
    "for i, resume in enumerate(perfect_resumes):\n",
    "    doc = Document()\n",
    "    \n",
    "    # Add personal information\n",
    "    doc.add_heading(resume['Personal Information']['Name'], 0)\n",
    "    \n",
    "    # Add skills\n",
    "    doc.add_heading('Skills', level=1)\n",
    "    doc.add_paragraph(resume['Skills'])\n",
    "    \n",
    "    # Add work experience\n",
    "    doc.add_heading('Work Experience', level=1)\n",
    "    for exp in resume['Work Experience']:\n",
    "        if exp:\n",
    "            doc.add_paragraph(f\"{exp['Position']} at {exp['Company']} ({exp['Duration']})\")\n",
    "            doc.add_paragraph(exp['Responsibilities'])\n",
    "            doc.add_paragraph()\n",
    "    \n",
    "    # Add education\n",
    "    if resume['Education']:\n",
    "        doc.add_heading('Education', level=1)\n",
    "        doc.add_paragraph(f\"{resume['Education']['Degree']} in {resume['Education']['Field']}\")\n",
    "        doc.add_paragraph(f\"{resume['Education']['University']}\")\n",
    "    \n",
    "    # Add additional sections\n",
    "    if resume['Programming Languages']:\n",
    "        doc.add_heading('Programming Languages', level=1)\n",
    "        doc.add_paragraph(resume['Programming Languages'])\n",
    "    \n",
    "    if resume['Data Science Skills']:\n",
    "        doc.add_heading('Data Science Skills', level=1)\n",
    "        doc.add_paragraph(resume['Data Science Skills'])\n",
    "    \n",
    "    if resume['Tools & Technologies']:\n",
    "        doc.add_heading('Tools & Technologies', level=1)\n",
    "        doc.add_paragraph(resume['Tools & Technologies'])\n",
    "    \n",
    "    if resume['Domain Expertise']:\n",
    "        doc.add_heading('Domain Expertise', level=1)\n",
    "        doc.add_paragraph(resume['Domain Expertise'])\n",
    "    \n",
    "    if resume['Specialized Skills']:\n",
    "        doc.add_heading('Specialized Skills', level=1)\n",
    "        doc.add_paragraph(resume['Specialized Skills'])\n",
    "    \n",
    "    # Save the document\n",
    "    save_path = os.path.join(save_dir, f\"perfect_resume_{i+1}.docx\")\n",
    "    doc.save(save_path)\n",
    "    print(f\"Perfect resume {i+1} saved as {save_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XFXCiT8GWgdP"
   },
   "source": [
    "#### 7. Inputs of CV and JD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Resume**:\n",
    "\n",
    "Get a random resume from our resume dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BK-fllx0WglI"
   },
   "outputs": [],
   "source": [
    "# Get a list of all .docx resume files\n",
    "resumes = [f for f in os.listdir('./dataset/resumes') if f.endswith('.docx')]\n",
    "\n",
    "# Select a random .docx file\n",
    "random_resume = random.choice(resumes)\n",
    "\n",
    "# Create a Document object\n",
    "doc = Document(os.path.join('./dataset/resumes', random_resume))\n",
    "\n",
    "# Extract text\n",
    "resume = \"\"\n",
    "for para in doc.paragraphs:\n",
    "    resume += para.text\n",
    "    \n",
    "print(resume)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Job Description**:\n",
    "\n",
    "Get a random JD from dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Select a random JD from the dataset\n",
    "# random_jd = random.choice(df['data'])\n",
    "\n",
    "random_jd = df.sample(1)['data'].values[0]\n",
    "print(\"Random JD:\", random_jd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the corresponding perfect resume for the random JD\n",
    "perfect_resume = perfect_resumes[df['data'].tolist().index(random_jd)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Develop a function to pre-process input text**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nY1-Fn97WgoN"
   },
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    # Remove URLs\n",
    "    text = re.sub('http\\S+\\s*', ' ', text)\n",
    "\n",
    "    # Remove RT and cc\n",
    "    text = re.sub('RT|cc', ' ', text)\n",
    "\n",
    "    # Remove hashtags\n",
    "    text = re.sub('#\\S+', '', text)\n",
    "\n",
    "    # Remove mentions\n",
    "    text = re.sub('@\\S+', '  ', text)\n",
    "    \n",
    "    # Convert the text to lowercase\n",
    "    text = text.lower()\n",
    "    \n",
    "    # Remove punctuation from the text\n",
    "    text = re.sub('[^a-z]', ' ', text)\n",
    "    \n",
    "    # Remove numerical values from the text\n",
    "    text = re.sub(r'\\d+', '', text)\n",
    "    \n",
    "    # Remove extra whitespaces\n",
    "    text = ' '.join(text.split())\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "J4TR1IklWqp8"
   },
   "outputs": [],
   "source": [
    "# Convert the perfect_resume dictionary to a string\n",
    "perfect_resume_str = json.dumps(perfect_resume)\n",
    "\n",
    "# Apply preprocess function to CV, JD, and perfect resume\n",
    "input_CV = preprocess_text(resume)\n",
    "input_JD = preprocess_text(random_jd)\n",
    "perfect_resume_text = preprocess_text(perfect_resume_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8. Matching\n",
    "Using the trained model, we infer the document vectors for the resume and job description. Then, we calculate the cosine similarity between the two vectors to determine the match between the resume and the job description."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate cosine similarity\n",
    "def calculate_similarity(vector1, vector2):\n",
    "    return cosine_similarity([vector1], [vector2])[0][0]\n",
    "\n",
    "# Infer vectors for the random resume, random JD, and perfect resume\n",
    "random_resume_vector = model.infer_vector(word_tokenize(input_CV))\n",
    "random_jd_vector = model.infer_vector(word_tokenize(input_JD))\n",
    "perfect_resume_vector = model.infer_vector(word_tokenize(perfect_resume_text))\n",
    "\n",
    "# Calculate similarity scores\n",
    "random_resume_similarity = calculate_similarity(random_resume_vector, random_jd_vector)\n",
    "perfect_resume_similarity = calculate_similarity(perfect_resume_vector, random_jd_vector)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 9. Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization\n",
    "fig1 = go.Figure(go.Indicator(\n",
    "    mode=\"gauge+number\",\n",
    "    value=random_resume_similarity * 100,\n",
    "    title={'text': \"Random Resume Matching Score (%)\"},\n",
    "    gauge={\n",
    "        'axis': {'range': [0, 100]},\n",
    "        'steps': [\n",
    "            {'range': [0, 50], 'color': \"#FFB6C1\"},\n",
    "            {'range': [50, 70], 'color': \"#FFFFE0\"},\n",
    "            {'range': [70, 100], 'color': \"#90EE90\"}\n",
    "        ],\n",
    "        'threshold': {'line': {'color': \"red\", 'width': 4}, 'thickness': 0.75, 'value': 100}\n",
    "    }\n",
    "))\n",
    "\n",
    "fig1.update_layout(width=400, height=400)  # Adjust the width and height as desired\n",
    "fig1.show()\n",
    "\n",
    "fig2 = go.Figure(go.Indicator(\n",
    "    mode=\"gauge+number\",\n",
    "    value=perfect_resume_similarity * 100,\n",
    "    title={'text': \"Perfect Resume Matching Score (%)\"},\n",
    "    gauge={\n",
    "        'axis': {'range': [0, 100]},\n",
    "        'steps': [\n",
    "            {'range': [0, 50], 'color': \"#FFB6C1\"},\n",
    "            {'range': [50, 70], 'color': \"#FFFFE0\"},\n",
    "            {'range': [70, 100], 'color': \"#90EE90\"}\n",
    "        ],\n",
    "        'threshold': {'line': {'color': \"red\", 'width': 4}, 'thickness': 0.75, 'value': 100}\n",
    "    }\n",
    "))\n",
    "\n",
    "fig2.update_layout(width=400, height=400)  # Adjust the width and height as desired\n",
    "fig2.show()\n",
    "\n",
    "# Print results\n",
    "print(\"\\nRandom Resume Matching Score:\", random_resume_similarity * 100, \"%\")\n",
    "print(\"Perfect Resume Matching Score:\", perfect_resume_similarity * 100, \"%\")\n",
    "\n",
    "if random_resume_similarity < 0.5:\n",
    "    print(colored(\"Low chance, need to modify your CV!\", \"red\", attrs=[\"bold\"]))\n",
    "elif random_resume_similarity >= 0.5 and random_resume_similarity < 0.7:\n",
    "    print(colored(\"Good chance but you can improve further!\", \"yellow\", attrs=[\"bold\"]))\n",
    "else:\n",
    "    print(colored(\"Excellent! You can submit your CV.\", \"green\", attrs=[\"bold\"]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 10. Run ATS model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Input JD Input in text below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # JD by input text:\n",
    "# jd = input(\"Paste your JD here: \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uMuC1hBtWqmr"
   },
   "outputs": [],
   "source": [
    "# jd = \"\"\"\n",
    "# Proactively engage with clients in the branch and deliver an outstanding service experience through completing transactions and by identifying opportunities for advice, solutions, digital enablement and partner introductions\n",
    "# Focus on education and demonstration, leverage technology to deliver a memorable client experience, drive solutions and retain business\n",
    "# Contribute to team results by listening and spotting opportunities to offer additional advice, introduce clients to the capability of RBC partners, or personally fulfil client solutions\n",
    "# Proactively take ownership of resolving and preventing client banking problems\n",
    "# Cultivate and maintain relationships with partners to work as one RBC team\n",
    "# Manage risks by adhering to compliance routines, processes, and controls to protect client and shareholder interests while completing transactions\n",
    "# What do you need to succeed?\n",
    "\n",
    "# Must-have\n",
    "\n",
    "# Goal-oriented individual with a demonstrated passion for putting clients first.\n",
    "# Drive and self-motivation, as well as excellent communication skills and emotional intelligence\n",
    "# Digital literacy across a broad range of devices (i.e., smartphones, tablets, laptops, etc.)\n",
    "# Personal flexibility to work flex hours\n",
    "# Eagerness to learn and determination to succeed\n",
    "# Confidence and ability to learn financial concepts and willingness to obtain the Investment Funds in Canada or the Canadian Securities Course\n",
    "# Nice-to-have\n",
    "\n",
    "# Track record in building rapport and maintaining client relationships within the financial, service or retail industry\n",
    "# Mutual Funds accreditation\n",
    "# Is this job right for you? Check out our video and decide for yourself!\n",
    "\n",
    "# What’s in it for you?\n",
    "\n",
    "# We thrive on the challenge to be our best, progressive thinking to keep growing, and working together to deliver trusted advice to help our clients thrive and communities prosper. We care about each other, reaching our potential, making a difference to our communities, and achieving success that is mutual.\n",
    "\n",
    "# A comprehensive Total Rewards Program including bonuses and flexible benefits, competitive compensation, commissions, and stock where applicable\n",
    "# A world-class training program in financial services\n",
    "# Excellent career development and access to a variety of job opportunities across business and geographies\n",
    "# Leaders who support your development through coaching and managing opportunities\n",
    "# Work in a dynamic, collaborative, progressive, and high-performing team\n",
    "# We also strive to provide an accessible candidate experience for our prospective employees with different abilities. Please let us know if you need any accommodations during the recruitment process.\n",
    "\n",
    "# Join our Talent Community\n",
    "\n",
    "# Stay in-the-know about great career opportunities at RBC. Sign up and get customized info on our latest jobs, career tips and Recruitment events that matter to you.\n",
    "\n",
    "# Expand your limits and create a new future together at RBC. Find out how we use our passion and drive to enhance the well-being of our clients and communities at rbc.com/careers.\n",
    "# \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
